{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required libraries\n",
    "import glob\n",
    "import os\n",
    "import posixpath\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printPoints(image_file, points):\n",
    "    \n",
    "    points = points.reshape((int(points.shape[0]/2),2))\n",
    "    \n",
    "    ori_image = cv2.imread(image_file)\n",
    "\n",
    "    for (x, y) in points:\n",
    "        cv2.circle(ori_image, (int(x),int(y)), 0, (0, 255, 0), -1)\n",
    "\n",
    "    plt.imshow(cv2.cvtColor(ori_image, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datasetToCSV(trainPath, testPath):\n",
    "    \n",
    "    train_path =posixpath.join(trainPath, \"*.png\")\n",
    "    train_images= np.array(glob.glob(train_path, ))\n",
    "    for i, image in enumerate(train_images):\n",
    "        train_images[i] = train_images[i].replace(\"\\\\\", \"/\")\n",
    "\n",
    "    train_landmarks = np.array([])\n",
    "    for i, image_file in enumerate(train_images):\n",
    "        points_file= image_file.replace(\"png\", \"pts\")\n",
    "\n",
    "        points=np.genfromtxt(points_file, delimiter=' ')\n",
    "\n",
    "        points = points.flatten()\n",
    "        if(i == 0):\n",
    "            train_landmarks = np.hstack((train_landmarks,points))\n",
    "        else:\n",
    "            train_landmarks = np.vstack((train_landmarks,points))\n",
    "    \n",
    "    test_path =posixpath.join(testPath, \"*.png\")\n",
    "    test_images= np.array(glob.glob(test_path, ))\n",
    "    for i, image in enumerate(test_images):\n",
    "        test_images[i] = test_images[i].replace(\"\\\\\", \"/\")\n",
    "    test_landmarks = np.array([])\n",
    "    for i, image_file in enumerate(test_images):\n",
    "        points_file= image_file.replace(\"png\", \"pts\")\n",
    "\n",
    "        points=np.genfromtxt(points_file, delimiter=' ')\n",
    "\n",
    "        points = points.flatten()\n",
    "        if(i == 0):\n",
    "            test_landmarks = np.hstack((test_landmarks,points))\n",
    "        else:\n",
    "            test_landmarks = np.vstack((test_landmarks,points))\n",
    "            \n",
    "    \n",
    "    land_cols = []\n",
    "    for i in range(136):\n",
    "        land_cols.append(\"Land{}\".format(i))\n",
    "        \n",
    "    for i, image in enumerate(test_images):\n",
    "        test_images[i] = test_images[i].split('/')[-1]\n",
    "        \n",
    "    for i, image in enumerate(train_images):\n",
    "        train_images[i] = train_images[i].split('/')[-1]\n",
    "        \n",
    "    train_path_df = pd.DataFrame(train_images, columns = [\"Path\"])\n",
    "    train_land_df = pd.DataFrame(train_landmarks, columns = land_cols)\n",
    "    \n",
    "    train_df = pd.concat([train_path_df, train_land_df], axis=1)\n",
    "    \n",
    "    test_path_df = pd.DataFrame(test_images, columns = [\"Path\"])\n",
    "    test_land_df = pd.DataFrame(test_landmarks, columns = land_cols)\n",
    "    \n",
    "    test_df = pd.concat([test_path_df, test_land_df], axis=1)\n",
    "    \n",
    "    train_df.to_csv('data/train.csv', index=False)\n",
    "    test_df.to_csv('data/test.csv', index=False)\n",
    "\n",
    "\n",
    "    return train_images, train_landmarks, test_images, test_landmarks\n",
    "    \n",
    "train_images, train_landmarks, test_images, test_landmarks = datasetToCSV(\"bbimages224/train/\", \"bbimages224/test/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LandmarkDataset(Dataset):\n",
    "    \"\"\"300W Landmark dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, img_dir):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file: Path to the csv file with image paths and landmarks.\n",
    "            img_dir: Directory with all the images.\n",
    "        \"\"\"\n",
    "        self.landmarks = pd.read_csv(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.landmarks)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = os.path.join(self.img_dir, self.landmarks.iloc[index, 0])\n",
    "        \n",
    "        image = mpimg.imread(image_path)\n",
    "        \n",
    "        # if image has an alpha color channel, get rid of it\n",
    "        if(image.shape[2] == 4):\n",
    "            image = image[:,:,0:3]\n",
    "        \n",
    "        landmarks = self.landmarks.iloc[index, 1:].to_numpy()\n",
    "        landmarks = landmarks.astype('float').reshape((int(landmarks.shape[0]/2),2))\n",
    "        sample = {'image': image, 'keypoints': key_pts}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset:  480\n"
     ]
    }
   ],
   "source": [
    "# Construct the dataset\n",
    "landmark_dataset = LandmarkDataset(csv_file='data/train.csv', img_dir='bbimages224/train/')\n",
    "\n",
    "# print some stats about the dataset\n",
    "print('Length of dataset: ', len(landmark_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 2.]\n",
      "[[1. 2.]\n",
      " [1. 2.]]\n"
     ]
    }
   ],
   "source": [
    "k = np.array([])\n",
    "l = np.array([1,2])\n",
    "k = np.hstack((k,l))\n",
    "print(k)\n",
    "k = np.vstack((k,l))\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2. 1. 2.]\n",
      " [1. 2. 1. 2.]]\n"
     ]
    }
   ],
   "source": [
    "h = np.array([[1.2, 1.5, 1.49, 1.9],[1.2, 1.5, 1.49, 1.9]])\n",
    "print(np.around(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.47213595499958"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.sum(np.square(np.around(h))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.040625"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true = np.array([[ 47.,35.],\n",
    " [ 68.,35.],\n",
    " [ 91.,33.],\n",
    " [108.,30.],\n",
    " [ 91.,59.]])\n",
    "\n",
    "pred = np.array([[ 50.,36.],\n",
    " [ 67.,34.],\n",
    " [ 91.,33.],\n",
    " [105.,29.],\n",
    " [ 91.,61.]])\n",
    "\n",
    "d = np.sqrt(128*128)\n",
    "nme = 0\n",
    "for i in range(len(true)):\n",
    "    nme+=(np.sum(np.square(true[i]-pred[i]))/d)\n",
    "\n",
    "nme = nme/5\n",
    "nme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
